{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Starbucks Capstone Challenge\n\n### Introduction\n\nThis data set contains simulated data that mimics customer behavior on the Starbucks rewards mobile app. Once every few days, Starbucks sends out an offer to users of the mobile app. An offer can be merely an advertisement for a drink or an actual offer such as a discount or BOGO (buy one get one free). Some users might not receive any offer during certain weeks. \n\nNot all users receive the same offer, and that is the challenge to solve with this data set.\n\nYour task is to combine transaction, demographic and offer data to determine which demographic groups respond best to which offer type. This data set is a simplified version of the real Starbucks app because the underlying simulator only has one product whereas Starbucks actually sells dozens of products.\n\nEvery offer has a validity period before the offer expires. As an example, a BOGO offer might be valid for only 5 days. You'll see in the data set that informational offers have a validity period even though these ads are merely providing information about a product; for example, if an informational offer has 7 days of validity, you can assume the customer is feeling the influence of the offer for 7 days after receiving the advertisement.\n\nYou'll be given transactional data showing user purchases made on the app including the timestamp of purchase and the amount of money spent on a purchase. This transactional data also has a record for each offer that a user receives as well as a record for when a user actually views the offer. There are also records for when a user completes an offer. \n\nKeep in mind as well that someone using the app might make a purchase through the app without having received an offer or seen an offer.\n\n### Example\n\nTo give an example, a user could receive a discount offer buy 10 dollars get 2 off on Monday. The offer is valid for 10 days from receipt. If the customer accumulates at least 10 dollars in purchases during the validity period, the customer completes the offer.\n\nHowever, there are a few things to watch out for in this data set. Customers do not opt into the offers that they receive; in other words, a user can receive an offer, never actually view the offer, and still complete the offer. For example, a user might receive the \"buy 10 dollars get 2 dollars off offer\", but the user never opens the offer during the 10 day validity period. The customer spends 15 dollars during those ten days. There will be an offer completion record in the data set; however, the customer was not influenced by the offer because the customer never viewed the offer.\n\n### Cleaning\n\nThis makes data cleaning especially important and tricky.\n\nYou'll also want to take into account that some demographic groups will make purchases even if they don't receive an offer. From a business perspective, if a customer is going to make a 10 dollar purchase without an offer anyway, you wouldn't want to send a buy 10 dollars get 2 dollars off offer. You'll want to try to assess what a certain demographic group will buy when not receiving any offers.\n\n### Final Advice\n\nBecause this is a capstone project, you are free to analyze the data any way you see fit. For example, you could build a machine learning model that predicts how much someone will spend based on demographics and offer type. Or you could build a model that predicts whether or not someone will respond to an offer. Or, you don't need to build a machine learning model at all. You could develop a set of heuristics that determine what offer you should send to each customer (i.e., 75 percent of women customers who were 35 years old responded to offer A vs 40 percent from the same demographic to offer B, so send offer A).","metadata":{}},{"cell_type":"markdown","source":"# Ref \n[link](https://github.com/hamadalaqeel/Starbuck-s-Capstone-Project/blob/master/Starbucks_Capstone_notebook.ipynb)","metadata":{}},{"cell_type":"markdown","source":"# Data Sets\n\nThe data is contained in three files:\n\n* portfolio.json - containing offer ids and meta data about each offer (duration, type, etc.)\n* profile.json - demographic data for each customer\n* transcript.json - records for transactions, offers received, offers viewed, and offers completed\n\nHere is the schema and explanation of each variable in the files:\n\n**portfolio.json**\n* id (string) - offer id\n* offer_type (string) - type of offer ie BOGO, discount, informational\n* difficulty (int) - minimum required spend to complete an offer\n* reward (int) - reward given for completing an offer\n* duration (int) - time for offer to be open, in days\n* channels (list of strings)\n\n**profile.json**\n* age (int) - age of the customer \n* became_member_on (int) - date when customer created an app account\n* gender (str) - gender of the customer (note some entries contain 'O' for other rather than M or F)\n* id (str) - customer id\n* income (float) - customer's income\n\n**transcript.json**\n* event (str) - record description (ie transaction, offer received, offer viewed, etc.)\n* person (str) - customer id\n* time (int) - time in hours since start of test. The data begins at time t=0\n* value - (dict of strings) - either an offer id or transaction amount depending on the record\n","metadata":{}},{"cell_type":"markdown","source":"# Business Understanding\n\nThe objective here is to find patterns and show when and where to give specific offer to a specific customer.","metadata":{}},{"cell_type":"code","source":"# Import relevant modules to project\nimport pandas as pd\nimport numpy as np\nimport math\nimport json\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import r2_score, mean_squared_error\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import StandardScaler\n\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2022-04-15T12:13:15.781800Z","iopub.execute_input":"2022-04-15T12:13:15.782767Z","iopub.status.idle":"2022-04-15T12:13:15.792495Z","shell.execute_reply.started":"2022-04-15T12:13:15.782726Z","shell.execute_reply":"2022-04-15T12:13:15.791441Z"},"trusted":true},"execution_count":219,"outputs":[]},{"cell_type":"code","source":"# Read the json files\nportfolio = pd.read_json('../input/udacity-starbucks-capstone-project/portfolio.json', orient='records', lines=True)\nprofile = pd.read_json('../input/udacity-starbucks-capstone-project/profile.json', orient='records', lines=True)\ntranscript = pd.read_json('../input/udacity-starbucks-capstone-project/transcript.json', orient='records', lines=True)\n\n\n# portfolio = pd.read_json('../input/udacity-starbucks-capstone-project/portfolio.json', orient='records')\n# profile = pd.read_json('../input/udacity-starbucks-capstone-project/profile.json', orient='records')\n# transcript = pd.read_json('../input/udacity-starbucks-capstone-project/transcript.json', orient='records')","metadata":{"execution":{"iopub.status.busy":"2022-04-15T12:13:15.952857Z","iopub.execute_input":"2022-04-15T12:13:15.953277Z","iopub.status.idle":"2022-04-15T12:13:18.931537Z","shell.execute_reply.started":"2022-04-15T12:13:15.953227Z","shell.execute_reply":"2022-04-15T12:13:18.930441Z"},"trusted":true},"execution_count":220,"outputs":[]},{"cell_type":"markdown","source":"# 1. Data Cleaning\n## 1.1. Porfolio\n- Update the name of the id column to offer_id.\n- Divide the channels into a number of columns.\n- Offer_type should be split across different columns.\n","metadata":{}},{"cell_type":"code","source":"portfolio.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-15T12:13:18.933798Z","iopub.execute_input":"2022-04-15T12:13:18.934118Z","iopub.status.idle":"2022-04-15T12:13:18.949933Z","shell.execute_reply.started":"2022-04-15T12:13:18.934074Z","shell.execute_reply":"2022-04-15T12:13:18.948867Z"},"trusted":true},"execution_count":221,"outputs":[]},{"cell_type":"code","source":"portfolio.describe()","metadata":{"execution":{"iopub.status.busy":"2022-04-15T12:13:18.951471Z","iopub.execute_input":"2022-04-15T12:13:18.952468Z","iopub.status.idle":"2022-04-15T12:13:18.983241Z","shell.execute_reply.started":"2022-04-15T12:13:18.952404Z","shell.execute_reply":"2022-04-15T12:13:18.982158Z"},"trusted":true},"execution_count":222,"outputs":[]},{"cell_type":"code","source":"portfolio.info()","metadata":{"execution":{"iopub.status.busy":"2022-04-15T12:13:18.986249Z","iopub.execute_input":"2022-04-15T12:13:18.986649Z","iopub.status.idle":"2022-04-15T12:13:19.002590Z","shell.execute_reply.started":"2022-04-15T12:13:18.986592Z","shell.execute_reply":"2022-04-15T12:13:19.001434Z"},"trusted":true},"execution_count":223,"outputs":[]},{"cell_type":"code","source":"# Update the name of the id column to offer_id.\nportfolio.rename(columns={'id':'offer_id'},inplace=True)\n\n# Divide the channels into a number of columns.\nchannel_dummies = pd.get_dummies(portfolio['channels'].apply(pd.Series).stack(), prefix='channel').sum(level=0)\nportfolio = pd.concat([portfolio,channel_dummies],axis=1)\nportfolio.drop(columns=['channels'],inplace=True)\n\n# Result:\nportfolio.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-15T12:13:19.004579Z","iopub.execute_input":"2022-04-15T12:13:19.004955Z","iopub.status.idle":"2022-04-15T12:13:19.035592Z","shell.execute_reply.started":"2022-04-15T12:13:19.004898Z","shell.execute_reply":"2022-04-15T12:13:19.034593Z"},"trusted":true},"execution_count":224,"outputs":[]},{"cell_type":"markdown","source":"## 1.2. Profile\n- Replace the name \"id\" with \"customer_id\".\n- Fix the date.\n- Irregular ages in the \"age\" column.\n- In the gender and income columns, there are 17,000 - 14,825 = 2,175 missing values.","metadata":{}},{"cell_type":"code","source":"profile.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-15T12:13:19.037302Z","iopub.execute_input":"2022-04-15T12:13:19.037673Z","iopub.status.idle":"2022-04-15T12:13:19.052696Z","shell.execute_reply.started":"2022-04-15T12:13:19.037627Z","shell.execute_reply":"2022-04-15T12:13:19.049563Z"},"trusted":true},"execution_count":225,"outputs":[]},{"cell_type":"code","source":"profile.info()","metadata":{"execution":{"iopub.status.busy":"2022-04-15T12:13:19.055002Z","iopub.execute_input":"2022-04-15T12:13:19.056070Z","iopub.status.idle":"2022-04-15T12:13:19.075354Z","shell.execute_reply.started":"2022-04-15T12:13:19.056024Z","shell.execute_reply":"2022-04-15T12:13:19.074209Z"},"trusted":true},"execution_count":226,"outputs":[]},{"cell_type":"code","source":"profile.describe()","metadata":{"execution":{"iopub.status.busy":"2022-04-15T12:13:19.076930Z","iopub.execute_input":"2022-04-15T12:13:19.077373Z","iopub.status.idle":"2022-04-15T12:13:19.104380Z","shell.execute_reply.started":"2022-04-15T12:13:19.077313Z","shell.execute_reply":"2022-04-15T12:13:19.103394Z"},"trusted":true},"execution_count":227,"outputs":[]},{"cell_type":"code","source":"# Replace the name \"id\" with \"customer_id\".\nprofile.rename(columns={'id':'customer_id'},inplace=True)\n\n# Fix the date.\nprofile['became_member_on'] = profile['became_member_on'].apply(lambda x: pd.to_datetime(str(x),format='%Y%m%d'))\n\n# Handle missing values in \"gender\" & \"income\" column.\n# gender_dummies = pd.get_dummies(profile['gender'],prefix='gender')\n# profile = pd.concat([profile.drop(columns=['gender']),gender_dummies],axis=1)\n# profile['gender'].fillna('NA', inplace=True)\nprofile['income'].fillna((profile['income'].mean()), inplace=True)\n\n# Some customers who has the irregular ages. Take them out of the concern by adding a new column - \"valid\"\nages = profile['age'].unique()\nperct_old_ages = profile['age'][profile['age'] > 100].count()/profile['age'].count() * 100\nprint('''\nUnique ages in the df: {},\n% customers who has the age > 100: {} %\n'''.format(ages, round(perct_old_ages,2)))\nprofile['valid'] = profile['age'].apply(lambda x: 1 if x <= 100 else 0)\n\n# Result:\nprofile.head()\n\n\n## TO_DO: Not handling the missing values in \"income\" columns????????","metadata":{"execution":{"iopub.status.busy":"2022-04-15T12:13:19.106068Z","iopub.execute_input":"2022-04-15T12:13:19.106444Z","iopub.status.idle":"2022-04-15T12:13:22.033947Z","shell.execute_reply.started":"2022-04-15T12:13:19.106391Z","shell.execute_reply":"2022-04-15T12:13:22.032920Z"},"trusted":true},"execution_count":228,"outputs":[]},{"cell_type":"markdown","source":"## 1.3. Transcript\n- Rename the \"person\" column to \"customer_id\".\n- Get dummies for \"event\" column.\n- Unlist the values in \"value\" column.\n\n","metadata":{}},{"cell_type":"code","source":"transcript.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-15T12:13:22.038196Z","iopub.execute_input":"2022-04-15T12:13:22.038449Z","iopub.status.idle":"2022-04-15T12:13:22.052668Z","shell.execute_reply.started":"2022-04-15T12:13:22.038416Z","shell.execute_reply":"2022-04-15T12:13:22.051417Z"},"trusted":true},"execution_count":229,"outputs":[]},{"cell_type":"code","source":"transcript.info()","metadata":{"execution":{"iopub.status.busy":"2022-04-15T12:13:22.054913Z","iopub.execute_input":"2022-04-15T12:13:22.055303Z","iopub.status.idle":"2022-04-15T12:13:22.179777Z","shell.execute_reply.started":"2022-04-15T12:13:22.055255Z","shell.execute_reply":"2022-04-15T12:13:22.178439Z"},"trusted":true},"execution_count":230,"outputs":[]},{"cell_type":"code","source":"transcript.describe()","metadata":{"execution":{"iopub.status.busy":"2022-04-15T12:13:22.181766Z","iopub.execute_input":"2022-04-15T12:13:22.182114Z","iopub.status.idle":"2022-04-15T12:13:22.205870Z","shell.execute_reply.started":"2022-04-15T12:13:22.182063Z","shell.execute_reply":"2022-04-15T12:13:22.204849Z"},"trusted":true},"execution_count":231,"outputs":[]},{"cell_type":"code","source":"# Rename the \"person\" column to \"customer_id\".\ntranscript.rename(columns={'person':'customer_id'},inplace=True)\n\n# Get dummies for \"event\" column.\n# transcript['event'] = transcript['event'].apply(lambda x: x.replace(' ','_'))\n# event_dummies = pd.get_dummies(transcript['event'], prefix='event')\n# transcript = pd.concat([transcript.drop(columns=['event']), event_dummies], axis=1)\n\n# Unlist the values in \"value\" column.\ntranscript['offer_id'] = [list(x.values())[0]  if (list(x.keys())[0] in ['offer_id', 'offer id']) else np.nan for x in transcript['value']]\ntranscript['amount'] = [list(x.values())[0]  if (list(x.keys())[0] in ['amount']) else np.nan for x in transcript['value']]\ntranscript.drop(columns=['value'],inplace=True)\n\n\n# Result:\ntranscript.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-15T12:13:22.207635Z","iopub.execute_input":"2022-04-15T12:13:22.208221Z","iopub.status.idle":"2022-04-15T12:13:23.053448Z","shell.execute_reply.started":"2022-04-15T12:13:22.208172Z","shell.execute_reply":"2022-04-15T12:13:23.052387Z"},"trusted":true},"execution_count":232,"outputs":[]},{"cell_type":"markdown","source":"## 1.4. Merge datasets","metadata":{}},{"cell_type":"code","source":"df = pd.merge(transcript, profile, on='customer_id', how=\"left\")\ndf = pd.merge(df, portfolio, on='offer_id', how=\"left\")\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-15T12:13:23.055290Z","iopub.execute_input":"2022-04-15T12:13:23.055871Z","iopub.status.idle":"2022-04-15T12:13:23.422341Z","shell.execute_reply.started":"2022-04-15T12:13:23.055822Z","shell.execute_reply":"2022-04-15T12:13:23.421397Z"},"trusted":true},"execution_count":233,"outputs":[]},{"cell_type":"code","source":"# Simplify the offer_id:\noffer_ids = df['offer_id'].unique()\ncnt = 1\noffer_list = {}\nfor offer in offer_ids:\n    offer_list[offer] = 'X'+str(cnt)\n    cnt += 1\ndf['offer_id'] = df['offer_id'].apply(lambda x: offer_list[x] if (x in offer_list.keys()) else x)\n\n# Simplify the customer_id:\ncustomer_ids = profile['customer_id'].unique()\ncount = 1\ncustomer_list = {}\nfor cus in customer_ids:\n    customer_list[cus] = 'A'+str(count)\n    count += 1\ndf['customer_id'] = df['customer_id'].apply(lambda x: customer_list[x] if (x in customer_list.keys()) else x)\n\n# Add \"age_group\" for analysis purpose\ndf['age_group'] = pd.cut(df['age'], bins=[0, 12, 18, 21, 64, 200], \n                        labels=['child', 'teen', 'young adult', 'adult', 'elderly'])\n\ndf.head()\n\n# Example:\n# offer_list = {'ae264e3637204a6fb9bb56bc8210ddfd': 'X1',\n#                 '4d5c57ea9a6940dd891ad53e9dbe8da0': 'X2',\n#                 '9b98b8c7a33c4b65b9aebfe6a799e6d9': 'B3',\n#                 'f19421c1d4aa40978ebb69ca19b0e20d': 'B4',\n#                 '0b1e1539f2cc45b7b9fa7c272da2e1d7': 'D1',\n#                 '2298d6c36e964ae4a3e7e9706d1fb8c2': 'D2',\n#                 'fafdcd668e3743c1bb461111dcafc2a4': 'D3',\n#                 '2906b810c7d4411798c6938adc9daaa5': 'D4',\n#                 '3f207df678b143eea3cee63160fa8bed': 'I1',\n#                 '5a8bc65990b245e5a138643cd4eb9837': 'I2'}","metadata":{"execution":{"iopub.status.busy":"2022-04-15T12:13:23.423969Z","iopub.execute_input":"2022-04-15T12:13:23.424976Z","iopub.status.idle":"2022-04-15T12:13:23.827400Z","shell.execute_reply.started":"2022-04-15T12:13:23.424928Z","shell.execute_reply":"2022-04-15T12:13:23.826458Z"},"trusted":true},"execution_count":234,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Analyze\n## 2.1.  Univariate Exploration:\n\n1. What is the average income of a Starbucks customer?\n2. What is the average Starbucks customer's age?\n3. Which of the following promotions is the most common?\n4. What are the most common values in each column of each dataframe?\n5. In terms of transcripts, who is the most loyal customer?","metadata":{}},{"cell_type":"markdown","source":"Let's start with the first question:\n\n**1. What is the average income of a Starbucks customer?**","metadata":{}},{"cell_type":"code","source":"print('The average income for Starbucks customers: ', round(profile['income'].mean(),2))","metadata":{"execution":{"iopub.status.busy":"2022-04-15T12:13:23.829039Z","iopub.execute_input":"2022-04-15T12:13:23.829624Z","iopub.status.idle":"2022-04-15T12:13:23.837556Z","shell.execute_reply.started":"2022-04-15T12:13:23.829575Z","shell.execute_reply":"2022-04-15T12:13:23.836381Z"},"trusted":true},"execution_count":235,"outputs":[]},{"cell_type":"markdown","source":"**2. What is the average Starbucks customer's age?**","metadata":{}},{"cell_type":"code","source":"print('The average age for Starbucks customers: ', round(profile['age'].mean(),2))","metadata":{"execution":{"iopub.status.busy":"2022-04-15T12:13:23.839497Z","iopub.execute_input":"2022-04-15T12:13:23.840176Z","iopub.status.idle":"2022-04-15T12:13:23.850355Z","shell.execute_reply.started":"2022-04-15T12:13:23.840129Z","shell.execute_reply":"2022-04-15T12:13:23.849120Z"},"trusted":true},"execution_count":236,"outputs":[]},{"cell_type":"markdown","source":"**3. Which of the following promotions is the most common?**\n\nBogo and Discount seem the most and they are close to each other with bogo been slightly higher","metadata":{}},{"cell_type":"code","source":"def addlabels(x,y,rotation='horizontal'):\n    '''\n    INPUT:\n    - x: an array of x labels\n    - y: an array of y values\n    - rotation: the default is 'horizontal', could be changed to 'vertical' or a number of degree.\n    OUTPUT: the label values attached in each bar column.\n    '''\n    for i in range(len(x)):\n        plt.text(i,y[i]//2,y[i],horizontalalignment='center')","metadata":{"execution":{"iopub.status.busy":"2022-04-15T12:13:23.852232Z","iopub.execute_input":"2022-04-15T12:13:23.852656Z","iopub.status.idle":"2022-04-15T12:13:23.860075Z","shell.execute_reply.started":"2022-04-15T12:13:23.852606Z","shell.execute_reply":"2022-04-15T12:13:23.858941Z"},"trusted":true},"execution_count":237,"outputs":[]},{"cell_type":"code","source":"# Check the completed orders only\n\nplt.subplot(121)\ncount_offer_id = df[df['event'] == 'offer completed']['offer_id'].value_counts()\ncount_offer_id.plot(kind='bar',figsize=(15, 5), rot=45)\nplt.xlabel('Offer ID')\nplt.ylabel('Count')\nplt.title('Distribution of Completed Promotions for each offer')\naddlabels(count_offer_id.index, count_offer_id.values);\n\nplt.subplot(122)\ncount_offer_type = df['offer_type'].value_counts()\ncount_offer_type.plot(kind='bar',figsize=(15, 5), rot=45)\n# plt.xlabel('Offer Type')\nplt.ylabel('Count')\nplt.title('Offer Type Distribution')\naddlabels(count_offer_type.index, count_offer_type.values);\n\n","metadata":{"execution":{"iopub.status.busy":"2022-04-15T12:13:23.861778Z","iopub.execute_input":"2022-04-15T12:13:23.862897Z","iopub.status.idle":"2022-04-15T12:13:24.469997Z","shell.execute_reply.started":"2022-04-15T12:13:23.862846Z","shell.execute_reply":"2022-04-15T12:13:24.469010Z"},"trusted":true},"execution_count":238,"outputs":[]},{"cell_type":"markdown","source":"**4. What are the most common values in each column of each dataframe?**","metadata":{}},{"cell_type":"code","source":"plt.subplot(121)\ndf['age'].hist()\nplt.xlabel('Age')\nplt.ylabel('Count')\nplt.title('Age Distribution');\n\nplt.subplot(122)\ncount_age_group = df['age_group'].value_counts()\ncount_age_group.plot(kind='bar',figsize=(15, 5), rot=45)\n# plt.xlabel('Age Group')\n# plt.ylabel('Count')\nplt.title('Age Group Distribution')\naddlabels(count_age_group.index, count_age_group.values);\n\n","metadata":{"execution":{"iopub.status.busy":"2022-04-15T12:13:24.473414Z","iopub.execute_input":"2022-04-15T12:13:24.473643Z","iopub.status.idle":"2022-04-15T12:13:24.926565Z","shell.execute_reply.started":"2022-04-15T12:13:24.473613Z","shell.execute_reply":"2022-04-15T12:13:24.925586Z"},"trusted":true},"execution_count":239,"outputs":[]},{"cell_type":"code","source":"gender_count = df['gender'].value_counts()\ngender_count.plot(kind='bar',figsize=(15, 5), rot=0)\nplt.xlabel('Gender')\nplt.ylabel('Count')\nplt.title('Gender Distribution')\naddlabels(gender_count.index, gender_count.values);","metadata":{"execution":{"iopub.status.busy":"2022-04-15T12:13:24.928614Z","iopub.execute_input":"2022-04-15T12:13:24.928916Z","iopub.status.idle":"2022-04-15T12:13:25.202336Z","shell.execute_reply.started":"2022-04-15T12:13:24.928872Z","shell.execute_reply":"2022-04-15T12:13:25.201408Z"},"trusted":true},"execution_count":240,"outputs":[]},{"cell_type":"markdown","source":"Most are Adults and Males, interesting...","metadata":{}},{"cell_type":"markdown","source":"**5. In terms of transcripts, who is the most loyal customer?**","metadata":{}},{"cell_type":"code","source":"loyal_customer_count = df[(df['event'] == 'offer completed') | (df['event'] == 'transaction')].groupby(['customer_id', 'event'])['amount'].sum().reset_index()\nloyal_customer_count = loyal_customer_count.sort_values('amount',ascending=False).head()\n\n# Visualize\nloyal_cus = loyal_customer_count.set_index('customer_id')\nloyal_cus.plot(kind='bar',figsize=(15, 5), rot=0)\nplt.xlabel('Customer ID')\nplt.ylabel('Count')\nplt.title('Customer Distribution')\naddlabels(loyal_cus.index, loyal_cus['amount']);\n\nfor cus in loyal_customer_count['customer_id']:\n    print('''\n    Profile ID: {},\n    Number of Completed Offers: {},\n    Amount: {}\n    '''.format(cus\n               ,df[df['event'] == 'offer completed'].groupby('customer_id')['offer_id'].count().loc[cus]\n               ,round(loyal_customer_count[loyal_customer_count['customer_id']==cus]['amount'].values[0], 2))\n         )\n\n    ","metadata":{"execution":{"iopub.status.busy":"2022-04-15T12:13:25.204388Z","iopub.execute_input":"2022-04-15T12:13:25.205219Z","iopub.status.idle":"2022-04-15T12:13:26.185287Z","shell.execute_reply.started":"2022-04-15T12:13:25.205168Z","shell.execute_reply":"2022-04-15T12:13:26.184304Z"},"trusted":true},"execution_count":241,"outputs":[]},{"cell_type":"markdown","source":"## 2.2. Multvariate Exploration\n\n1. What is the most popular promotion among children, teenagers, young adults, adults, and the elderly?\n2. Which gender earns more money from profiles, guys or females?\n3. What kinds of promotions do each gender prefer?","metadata":{}},{"cell_type":"markdown","source":"**1. What is the most popular promotion among children, teenagers, young adults, adults, and the elderly?**","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15, 5))\nsns.countplot(data=df, x='age_group', hue='offer_type')\nplt.title('Offer Distribution by Age Group & Offer Type')\nplt.ylabel('Count')\nplt.xticks(rotation = 0)\nplt.legend(title='Offer Type')\nplt.show();","metadata":{"execution":{"iopub.status.busy":"2022-04-15T12:13:26.187000Z","iopub.execute_input":"2022-04-15T12:13:26.188557Z","iopub.status.idle":"2022-04-15T12:13:26.680390Z","shell.execute_reply.started":"2022-04-15T12:13:26.188506Z","shell.execute_reply":"2022-04-15T12:13:26.679277Z"},"trusted":true},"execution_count":242,"outputs":[]},{"cell_type":"markdown","source":"**2. Which gender earns more money from profiles, guys or females?**\n\nNote: Exclude N/A because they didn't tell their gender","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15, 5))\nsns.violinplot(x=df[df['gender'] != 'NA']['gender'], y=df['income'])\nplt.title('Income vs. Gender')\nplt.ylabel('Income')\nplt.xlabel('Gender')\nplt.xticks(rotation = 0)\nplt.show();","metadata":{"execution":{"iopub.status.busy":"2022-04-15T12:13:26.681919Z","iopub.execute_input":"2022-04-15T12:13:26.682250Z","iopub.status.idle":"2022-04-15T12:13:28.041322Z","shell.execute_reply.started":"2022-04-15T12:13:26.682202Z","shell.execute_reply":"2022-04-15T12:13:28.040374Z"},"trusted":true},"execution_count":243,"outputs":[]},{"cell_type":"markdown","source":"**Note:** The median is shown by the `white dot` in each graph.","metadata":{}},{"cell_type":"markdown","source":"**3. What kinds of promotions do each gender prefer?**","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15, 5))\nsns.countplot(data=df, x=df[df['gender'] != 'NA']['gender'], hue = 'offer_type')\nplt.title('Income vs Gender')\nplt.ylabel('Income')\nplt.xlabel('Gender')\nplt.xticks(rotation = 0)\nplt.show();","metadata":{"execution":{"iopub.status.busy":"2022-04-15T12:13:28.046734Z","iopub.execute_input":"2022-04-15T12:13:28.046995Z","iopub.status.idle":"2022-04-15T12:13:29.040170Z","shell.execute_reply.started":"2022-04-15T12:13:28.046964Z","shell.execute_reply":"2022-04-15T12:13:29.039036Z"},"trusted":true},"execution_count":244,"outputs":[]},{"cell_type":"markdown","source":"# 3. Simple Linear Regression Machine Learning Model\n\nBased on consumer age, income, and gender, the model attempts to forecast **amount spent per transaction.**","metadata":{}},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-15T12:13:29.041993Z","iopub.execute_input":"2022-04-15T12:13:29.042549Z","iopub.status.idle":"2022-04-15T12:13:29.071930Z","shell.execute_reply.started":"2022-04-15T12:13:29.042500Z","shell.execute_reply":"2022-04-15T12:13:29.070919Z"},"trusted":true},"execution_count":245,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# Extract df for the model\ndf_ml = df[['amount','gender','age','income','event']]\ndf_ml = pd.concat([pd.get_dummies(df_ml['event']), df_ml.drop(columns=['event'])], axis=1)\ndf_ml = df_ml[['amount','gender','age','income','transaction']]\n\ndf_ml = df_ml[(df_ml['transaction'] == 1) & (df_ml['gender'] != 'O')]\ndf_ml = pd.concat([pd.get_dummies(df_ml['gender']), df_ml.drop(columns=['gender'])], axis=1)\ndf_ml.drop(columns=['transaction'], axis=1, inplace=True)\n\ndf_ml.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-15T12:13:29.073682Z","iopub.execute_input":"2022-04-15T12:13:29.074272Z","iopub.status.idle":"2022-04-15T12:13:29.271392Z","shell.execute_reply.started":"2022-04-15T12:13:29.074223Z","shell.execute_reply":"2022-04-15T12:13:29.270401Z"},"trusted":true},"execution_count":246,"outputs":[]},{"cell_type":"code","source":"# Check NaN values\ndf_ml.isnull().mean()","metadata":{"execution":{"iopub.status.busy":"2022-04-15T12:13:29.273280Z","iopub.execute_input":"2022-04-15T12:13:29.273912Z","iopub.status.idle":"2022-04-15T12:13:29.288418Z","shell.execute_reply.started":"2022-04-15T12:13:29.273861Z","shell.execute_reply":"2022-04-15T12:13:29.287083Z"},"trusted":true},"execution_count":247,"outputs":[]},{"cell_type":"code","source":"# Define features and target as well as split train/test data\nX = df_ml.drop('amount', axis=1)\ny = df_ml['amount']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .30, random_state=42)\n\nscores = dict()","metadata":{"execution":{"iopub.status.busy":"2022-04-15T12:13:29.289539Z","iopub.execute_input":"2022-04-15T12:13:29.289772Z","iopub.status.idle":"2022-04-15T12:13:29.316466Z","shell.execute_reply.started":"2022-04-15T12:13:29.289741Z","shell.execute_reply":"2022-04-15T12:13:29.315532Z"},"trusted":true},"execution_count":248,"outputs":[]},{"cell_type":"code","source":"# No Scaling/Normalization Approach\n\n# Instantiate, Fit & Predict\nlr_dumb = LinearRegression(normalize=True) \nlr_dumb.fit(X_train, y_train) \ny_test_preds = lr_dumb.predict(X_test) \n\nscores['No Scaling/Normalization'] = round(r2_score(y_test, y_test_preds),2)\n\nprint(\n'''\nNo Scaling/Normalization: \nr-square score: {} on {} values.'''.format(round(r2_score(y_test, y_test_preds),2), len(y_test))\n)","metadata":{"execution":{"iopub.status.busy":"2022-04-15T12:13:29.318089Z","iopub.execute_input":"2022-04-15T12:13:29.318466Z","iopub.status.idle":"2022-04-15T12:13:29.348327Z","shell.execute_reply.started":"2022-04-15T12:13:29.318406Z","shell.execute_reply":"2022-04-15T12:13:29.347164Z"},"trusted":true},"execution_count":249,"outputs":[]},{"cell_type":"code","source":"# Normalization approach\n\n# Fit scaler on the training data\nnorm = MinMaxScaler().fit(X_train)\n\n# Transform\nX_train_norm = norm.transform(X_train)\nX_test_norm = norm.transform(X_test)\n\n# Instantiate, Fit & Predict\nlr_norm = LinearRegression(normalize=True) \nlr_norm.fit(X_train_norm, y_train) \ny_test_preds = lr_norm.predict(X_test_norm) \n\nscores['Normalization'] = round(r2_score(y_test, y_test_preds),2)\n\nprint(\n'''\nNormalization: \nr-square score: {} on {} values.'''.format(round(r2_score(y_test, y_test_preds),2), len(y_test))\n)\n","metadata":{"execution":{"iopub.status.busy":"2022-04-15T12:13:29.350350Z","iopub.execute_input":"2022-04-15T12:13:29.351014Z","iopub.status.idle":"2022-04-15T12:13:29.394645Z","shell.execute_reply.started":"2022-04-15T12:13:29.350940Z","shell.execute_reply":"2022-04-15T12:13:29.393444Z"},"trusted":true},"execution_count":250,"outputs":[]},{"cell_type":"code","source":"# Scalarization approach\n\n# Apply standardization on numerical features\nnum_cols = ['age','income']\nfor i in num_cols:\n    # Fit on training data column\n    scale = StandardScaler().fit(X_train_stand[[i]])\n    \n    # Transform\n    X_train_stand[i] = scale.transform(X_train_stand[[i]])\n    X_test_stand[i] = scale.transform(X_test_stand[[i]])\n    \n#Instantiate, Fit & Predict\nlr_stand = LinearRegression(normalize=True) \nlr_stand.fit(X_train_stand, y_train) \ny_test_preds = lr_stand.predict(X_test_stand)\n\nscores['Scalarization'] = round(r2_score(y_test, y_test_preds),2)\n\nprint(\n'''\nScalarization: \nr-square score: {} on {} values.'''.format(round(r2_score(y_test, y_test_preds),2), len(y_test))\n)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-04-15T12:13:29.396527Z","iopub.execute_input":"2022-04-15T12:13:29.397011Z","iopub.status.idle":"2022-04-15T12:13:29.460119Z","shell.execute_reply.started":"2022-04-15T12:13:29.396967Z","shell.execute_reply":"2022-04-15T12:13:29.459103Z"},"trusted":true},"execution_count":251,"outputs":[]},{"cell_type":"code","source":"score_df = pd.DataFrame()\nscore_df['model type'] = scores.keys()\nscore_df['r-square value'] = scores.values()\nscore_df","metadata":{"execution":{"iopub.status.busy":"2022-04-15T12:13:29.461885Z","iopub.execute_input":"2022-04-15T12:13:29.462447Z","iopub.status.idle":"2022-04-15T12:13:29.481394Z","shell.execute_reply.started":"2022-04-15T12:13:29.462398Z","shell.execute_reply":"2022-04-15T12:13:29.480254Z"},"trusted":true},"execution_count":252,"outputs":[]},{"cell_type":"markdown","source":"## Conclusion","metadata":{}},{"cell_type":"markdown","source":"The r-squared score was the same for all three ways. Let's take a look at the identical r-squared score as the previous item. In a linear regression model, characteristics are not assigned more weight based on their magnitude, as they would be in a distance-based method. Each feature converges on a minima in a linear regression model, which is a type of gradient descent model. When not scaled, the pace of descent and step size of each feature can vary. This does not give larger magnitude features a higher weight than lower magnitude features, but it can hurt model performance because some features decline to the minima faster than others. Scaling numerical data in a linear regression model is generally a good idea to improve model stability and convergence time. However, as the results in the preceding section show, it is not necessary in terms of feature weighting.\n\n\nThe r-squared value will be discussed in the second item. The r-squared number is based on a 0 to 100 percent scale, as described in the metrics section. The better the correlation and model accuracy in predicting, the higher the percentage. As a result, there is little link between consumer amount spent per transaction and age, gender, or annual income in the model above.","metadata":{}},{"cell_type":"markdown","source":"## Improvements","metadata":{}},{"cell_type":"markdown","source":"I believe I've arrived to a position where I have strong outcomes and a decent grasp of the data. However, in order to improve our results, I would strive to improve my data collecting and resolve any issues I have with NaN values. I'll also try to obtain further information, such as the place and time the transaction was made, as well as the branch and time of day. All of this information can assist us in determining when and where we should make our proposals.","metadata":{}}]}